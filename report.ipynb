{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "At the moment I have 2 types of networks, both with 10k excitatory neurons and same parameters. The first one is a random network, 5% connectivity, the other one is a topological network. Connectivity 5% but the connections are chosen via a Gaussian filter so that inhibitory neurons connect preferentially with the nearest neighbours, the excitatory ones have a bit wider range. \n",
      "Then I analysed the reciprocal connections. The paper by Chklovskii reported that cortical circuits have more bidirectional connections than one would expect in a random network. Thus, I wanted to check how the topological rules change that.\n",
      "The plots below show the ratio or bidirectional connections. For a given neuron I took all the target neurons and checked how many of those connect back to the source neuron.\n",
      "As expected, the numbers differ considerably for the two networks. Regardless of a type of a connection, in random nets the bidirectionality ratio is around 5%. In the topological network the ratio goes up to 50% for inh-inh connections. The ratio can be controlled by changing the parameters of the Gaussian filters that are used to pool the target neurons while connecting the network. I'm still considering what to do with this information. If cortical networks tend to have a higher bidirectionality ratio, shall I stick to this model? And then, while embedding a feedforward chain - will it make a difference to choose only the neurons that are (not) reciprocally connected? "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<figure>\n",
      "<img src=\"files/hist_random1400.png\" caption='random network'>\n",
      "<figcaption>Bidirectionality ratio for a random network with 5% connectivity</figcaption>\n",
      "</figure>\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "<figure>\n",
      "<img src=\"files/hist_topol1000.png\">\n",
      "<figcaption>Bidirectionality ratio for a topological network with 5% connectivity</figcaption>\n",
      "</figure>"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Then I moved on to the original plan to step by step embed feedforward connections. I chose to only do it in a random network not to be bothered with the decision about the choice of the neurons (based on their location, bidirectionality etc. - that will come soon)"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "I started with tiny examples of connecting a row of, say 5 excitatory neurons one after another (with the delayed inhibitory ones). But then I realised that this trick doesn't change a network at all:\n",
      "I randomly chose a neuron A and then I randomly chose a neuron B to connect to. But since it is all random, I can as well choose B to be a neuron that already is a target for A. So in essence the only alteration I make is connecting A with some inhibitory neuron I that already connects to B. \n",
      "Now we can run simulations and hope that as soon as the A fires, it will cause B and I to fire too.\n",
      "\n",
      "In practice it is very hard to achieve this since the networks parameters are set up so that every neuron receives dozens of inputs form excitatory and inhibitory neurons and, on average, the firing rates are low. It is very unlikely that A alone will excite both B and I (and then propagate the signal along the rest of the chain). See the plots below:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<figure>\n",
      "<img src=\"files/voltage1neuron.png\">\n",
      "<figcaption>Voltage of a neuron that receives only excitatory input. Resting potential is -70mV, Threshold = -57mV. The neuron is bombarded with spikes and even when those spikes are close to each other, the cell is far from reaching the threshold. </figcaption>\n",
      "</figure>\n",
      "\n",
      "<figure>\n",
      "<img src=\"files/voltage1neuron_spike.png\">\n",
      "<figcaption>Voltage of a neuron that receives only excitatory input. Here is an example when the neuron fires. It takes a lot of spikes to arrive almost simultaneously to depolarize the neuron.</figcaption>\n",
      "</figure>"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "The example above illustrates a neuron that receives only excitatory inputs. In a network every neuron will receive inhibitory inputs too so the voltage will oscillate around the resting potential. In such a regime, the only case when neuron A can excite both B and I is when membrane potential of both is nearly hitting the threshold. This case, however, is highly unlikely (not to mention the case with the whole long chain). \n",
      "One can also think that such single-neuron feedforward chains happen all the time - some neuron fires and excites all the connected neurons and some of them as a result fire too - and again excite another pool of neurons and so on. The delayed inhibition plays no role here, all that matters is that one neuron exited another one and the signal moved on. The obvious problem of course is that such 'chains' hardly ever repeat. It is a random network after all and there's no reason to expect that A will always excite B. \n",
      "\n",
      "\n",
      "Thus, one cannot embed a one-neuron chain into a random network with homogenous weights. \n",
      "\n",
      "How to move on from this? Two options will be considered. first one is keeping a one neuron chain but increasing the synapse strength, the other option is to increase a number of eurons in each gate within the chain.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<figure>\n",
      "<img src=\"files/raster50chainweight20.png\">\n",
      "<figcaption>raster plot of a 50-neuron long chain embedded in 10k net. Synapse strength along the chain was increased 20 times.</figcaption>\n",
      "</figure>\n",
      "\n",
      "<figure>\n",
      "<img src=\"files/raster50chainweight30.png\">\n",
      "<figcaption>raster plot of a 50-neuron long chain embedded in 10k net. Synapse strength along the chain was increased 30 times.</figcaption>\n",
      "</figure>\n",
      "\n",
      "<figure>\n",
      "<img src=\"files/raster200chainweight35.png\">\n",
      "<figcaption>raster plot of a 200-neuron long chain embedded in 10k net. Synapse strength along the chain was increased 35 times. </figcaption>\n",
      "</figure>\n",
      "\n",
      "<figure>\n",
      "<img src=\"files/raster200chainweight40.png\">\n",
      "<figcaption>raster plot of a 200-neuron long chain embedded in 10k net. Synapse strength along the chain was increased 40 times.</figcaption>\n",
      "</figure>"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "The plots above show rasterplots of 1-neuron-per-gate chains embedded in 10k network. The connections along the chain were strengthened 20, 30, 35 and 45 times. As the weights increase, one can notice some feedforward spontaneous activity but even if the weights are 40 times stronger, the signal fails to reach an end. The success of the propagation depends solely on the current membrane potential of the neuron that is about to receive the signal. If it's near the threshold, it will fire, if it is strongly hyperpolarized, even a strong input won't help to reach the threshold. One can agrue that this is an example of a 'spontanous activity' rather than input driven one. But if only one neuron is about to carry a signal, there is no difference how it was excited in the first place - whether it was an external source or intrinsic activity of the whole network. Overall, "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}